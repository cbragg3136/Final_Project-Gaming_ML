{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "nasty-pierre",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Down-sampling involves randomly removing observations from the majority class \n",
    "# to prevent its signal from dominating the learning algorithm.\n",
    "# Most common method is resampling without replacement\n",
    "\n",
    "# - First, we'll separate observations from each class into different DataFrames.\n",
    "# - Next, we'll resample the majority class without replacement, setting the number \n",
    "# of samples to match that of the minority class.\n",
    "# - Finally, we'll combine the down-sampled majority class DataFrame with \n",
    "# the original minority class DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "desirable-asset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load necessary python libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "conservative-yellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# module for resampling\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "spread-loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "angry-incidence",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# os.listdir(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fleet-tournament",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39624, 351)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the csv x_data file into Pandas \n",
    "\n",
    "all_param_df = pd.read_csv(\"..\\\\reduced_data\\\\all_param.csv\")\n",
    "all_param_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "according-restriction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate classes in dataframes of success/failure\n",
    "df_fail = all_param_df[all_param_df.suc_class==0]\n",
    "df_succ = all_param_df[all_param_df.suc_class==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "renewable-surrey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38818, 351)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fail.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ruled-stage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(806, 351)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_succ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "historical-possible",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1000\n",
       "1     806\n",
       "Name: suc_class, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downsample Majority class\n",
    "df_fail_downsample = resample(df_fail, replace=False, n_samples=1000, random_state=2)\n",
    "\n",
    "# combine success with downsampled majority class into new dataframe\n",
    "df_downsampled = pd.concat([df_fail_downsample, df_succ])\n",
    "\n",
    "# display new class counts\n",
    "df_downsampled.suc_class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "foreign-courtesy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reindex the new upsampled dataframe\n",
    "# df_upsampled.reindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "hybrid-education",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "intermediate-decrease",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read the csv y_data file into Pandas \n",
    "# y_parm_df = pd.read_csv(\"reduced_data\\\\y_params.csv\")\n",
    "# y_parm_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "standing-norman",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using binary classification for logistic regression\n",
    "y_class = df_downsampled['suc_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "official-dream",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13716    0\n",
       "4622     0\n",
       "1350     0\n",
       "30223    0\n",
       "23274    0\n",
       "        ..\n",
       "39619    1\n",
       "39620    1\n",
       "39621    1\n",
       "39622    1\n",
       "39623    1\n",
       "Name: suc_class, Length: 1806, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "hybrid-phrase",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new X parameters df\n",
    "x_data = df_downsampled.drop(['appid','maxccu','success_class','suc_class','followers']  , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "yellow-thanks",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1806, 346)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "moral-peninsula",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_class, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "loose-florida",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline example\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "general-performer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing  - scale the data using the MinMaxScaler and perform some feature selection\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "x_scaler = MinMaxScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dedicated-lucas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the trained scales (MinMax) to the training and testing data\n",
    "\n",
    "X_train_scaled = x_scaler.transform(X_train)\n",
    "X_test_scaled = x_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "stone-merchandise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "y = y_train\n",
    "X = X_train_scaled\n",
    "\n",
    "clf_2 = LogisticRegression(max_iter=1000).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "visible-offer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.4446085672082718\n",
      "Testing Data Score: 0.8097345132743363\n"
     ]
    }
   ],
   "source": [
    "# Apply fitted model to test data - what accuracy?\n",
    "print(f\"Training Data Score: {clf_2.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {clf_2.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "attempted-mining",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.98      0.85       248\n",
      "           1       0.95      0.61      0.74       204\n",
      "\n",
      "    accuracy                           0.81       452\n",
      "   macro avg       0.85      0.79      0.80       452\n",
      "weighted avg       0.84      0.81      0.80       452\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Understand precision, recall, f1 score with classification report for logistic classification\n",
    "from sklearn.metrics import classification_report\n",
    "predictions = clf_2.predict(X_test_scaled)\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "rolled-airport",
   "metadata": {},
   "outputs": [],
   "source": [
    "# thinking about baseline results:\n",
    "# Support is balanced due to sampling adjustments\n",
    "# Percision: for no success: 75%, for successful games: 95%\n",
    "# Recall: Fraction of positives found, 98% for 0, 61% for 1\n",
    "# f1 score: 81%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worthy-assessment",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pythondata] *",
   "language": "python",
   "name": "conda-env-pythondata-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
