{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "nasty-pierre",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Up-sampling effort: randomly duplicating observations from the minority class \n",
    "# to reinforce its signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "desirable-asset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load necessary python libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "interim-anderson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# module for resampling\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "spread-loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "angry-incidence",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# os.listdir(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fleet-tournament",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39624, 351)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the csv x_data file into Pandas \n",
    "\n",
    "all_param_df = pd.read_csv(\"..\\\\reduced_data\\\\all_param.csv\")\n",
    "all_param_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "diagnostic-junction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # separate classes in dataframes of success/failure\n",
    "# df_fail = all_param_df[all_param_df.suc_class==0]\n",
    "# df_succ = all_param_df[all_param_df.suc_class==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "powered-cotton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38818, 351)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_fail.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "printable-director",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(806, 351)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_succ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "animated-advice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Upsaple Minority class\n",
    "# df_succ_upsampled = resample(df_succ, replace=True, n_samples=38000, random_state=2)\n",
    "\n",
    "# # combine failed with upsampled minority class into new dataframe\n",
    "# df_upsampled = pd.concat([df_fail, df_succ_upsampled])\n",
    "\n",
    "# # display new class counts\n",
    "# df_upsampled.suc_class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "electoral-corpus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reindex the new upsampled dataframe\n",
    "# df_upsampled.reindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "declared-coverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "intermediate-decrease",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read the csv y_data file into Pandas \n",
    "# y_parm_df = pd.read_csv(\"reduced_data\\\\y_params.csv\")\n",
    "# y_parm_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "standing-norman",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using binary classification for logistic regression\n",
    "y_class = all_param_df['suc_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "official-dream",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "39619    1\n",
       "39620    1\n",
       "39621    1\n",
       "39622    1\n",
       "39623    1\n",
       "Name: suc_class, Length: 39624, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "administrative-aviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new X parameters df\n",
    "x_data = all_param_df.drop(['appid','maxccu','success_class','suc_class','followers']  , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "handy-biography",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39624, 346)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "improving-controversy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_class, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "loose-florida",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline example\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "outer-cholesterol",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing  - scale the data using the MinMaxScaler and perform some feature selection\n",
    "\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# x_scaler = MinMaxScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "retired-flesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the trained scales (MinMax) to the training and testing data\n",
    "\n",
    "# X_train_scaled = x_scaler.transform(X_train)\n",
    "# X_test_scaled = x_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "stone-merchandise",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wavau\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate and Train model\n",
    "y = y_train\n",
    "X = X_train\n",
    "\n",
    "clf_1 = LogisticRegression(max_iter=1000).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bacterial-pierce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.9866747425802543\n",
      "Testing Data Score: 0.9797092671108419\n"
     ]
    }
   ],
   "source": [
    "# Apply fitted model to test data - what accuracy?\n",
    "print(f\"Training Data Score: {clf_1.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {clf_1.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ahead-carolina",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      9701\n",
      "           1       0.51      0.45      0.48       205\n",
      "\n",
      "    accuracy                           0.98      9906\n",
      "   macro avg       0.75      0.72      0.74      9906\n",
      "weighted avg       0.98      0.98      0.98      9906\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Understand precision, recall, f1 score with classification report for logistic classification\n",
    "from sklearn.metrics import classification_report\n",
    "predictions = clf_1.predict(X_test)\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "received-transformation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# thinking about baseline results:\n",
    "# Support is not balanced - 9700 fail cases vs 205 success\n",
    "# Percision: for no success: 99%, better for successful games: 51%\n",
    "# Percision= % of labeling an outcome that is correct from all the labels of that outcome\n",
    "# labeled cancer correctly from all labeled cancer\n",
    "# Recall: Fraction of positives found, 96% for 0, 48% for 1\n",
    "# Recall - % of true label found from all true cases of the label\n",
    "# how many of the cancer cases did you find\n",
    "# f1 score: 98% due to overfitting on failure cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-effects",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pythondata] *",
   "language": "python",
   "name": "conda-env-pythondata-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
